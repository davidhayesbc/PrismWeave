# PrismWeave AI Processing - Simplified Configuration

# Ollama Server Configuration
ollama:
  host: http://localhost:11434
  timeout: 60
  models:
    embedding: 'nomic-embed-text:latest' # Vector embeddings for search
    tagging: 'phi3:mini' # Semantic tag generation (LLM)

# Document Processing Configuration
processing:
  chunk_size: 1000 # Smaller chunks for web documents
  chunk_overlap: 200 # Overlap between chunks

# Vector Database Configuration
vector:
  collection_name: 'documents'
  persist_directory: '../../PrismWeaveDocs/.prismweave/chroma_db'

# MCP Server Configuration
mcp:
  # Paths configuration
  paths:
    documents_root: '../../PrismWeaveDocs'
    documents_dir: 'documents'
    generated_dir: 'generated'
    images_dir: 'images'
    tech_dir: 'tech'

  # Search configuration
  search:
    max_results: 20
    similarity_threshold: 0.45
    default_filters: {}

  # Document creation settings
  creation:
    auto_process: true # Automatically generate tags and embeddings
    auto_commit: false # Don't auto-commit by default
    default_category: 'general'

  # Git integration
  git:
    auto_push: false
    commit_message_template: 'Add document: {title}'
    branch: 'main'

  # Rate limiting (requests per minute)
  rate_limiting:
    search: 60
    create: 30
    process: 20
